{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, re, random, glob, json, jieba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    TextGenerationPipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = \"/Users/zeyesun/Documents\"\n",
    "# root = \"/mnt/private-pa002-vol141056-prd\"\n",
    "root = \"D://\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_TEXT_PATTERN = re.compile(r\"[\\r\\n]\")\n",
    "\n",
    "def clean_text(text):\n",
    "    return CLEAN_TEXT_PATTERN.sub(\"\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece\n",
    "model_file = os.path.join(root,\"Data\", \"models\", \"pangu-350M\", \"vocab.model\")\n",
    "sp = sentencepiece.SentencePieceProcessor()\n",
    "sp.Load(model_file=model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk>\n",
      "<s>\n",
      "</s>\n",
      "▃\n",
      "▂\n",
      "<sep>\n",
      "<pad>\n",
      "<mask>\n",
      "<eod>\n",
      "<eot>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(sp.id_to_piece(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_or_path = os.path.join(root, \"Data\", \"models\", \"pangu-350M\")\n",
    "# model_name_or_path = os.path.join(root, \"Data\", \"models\", \"pangu-2.6B\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "tokenizer.add_special_tokens({\n",
    "    'unk_token': \"<unk>\", \n",
    "    'eos_token': \"<eot>\", \n",
    "    'pad_token': \"<pad>\", \n",
    "    \"sep_token\": \"<sep>\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Some weights of GPTPanguForCausalLM were not initialized from the model checkpoint at D:\\Data\\models\\pangu-350M and are newly initialized: ['transformer.h.23.attn.masked_bias', 'transformer.h.11.attn.bias', 'transformer.h.15.attn.bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.5.attn.bias', 'transformer.h.22.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.6.attn.bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.15.attn.masked_bias', 'transformer.h.16.attn.masked_bias', 'transformer.h.12.attn.masked_bias', 'transformer.h.14.attn.bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.8.attn.bias', 'transformer.h.9.attn.bias', 'lm_head.weight', 'transformer.h.13.attn.masked_bias', 'transformer.h.3.attn.bias', 'transformer.h.1.attn.bias', 'transformer.h.23.attn.bias', 'transformer.h.14.attn.masked_bias', 'transformer.h.12.attn.bias', 'transformer.h.0.attn.bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.18.attn.masked_bias', 'transformer.h.18.attn.bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.19.attn.masked_bias', 'transformer.h.21.attn.bias', 'transformer.h.17.attn.masked_bias', 'transformer.h.20.attn.masked_bias', 'transformer.h.21.attn.masked_bias', 'transformer.h.20.attn.bias', 'transformer.h.7.attn.bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.16.attn.bias', 'transformer.h.2.attn.bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.10.attn.bias', 'transformer.h.22.attn.bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.13.attn.bias', 'transformer.h.19.attn.bias', 'transformer.h.17.attn.bias', 'transformer.h.4.attn.bias', 'transformer.h.5.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTPanguForCausalLM(\n",
       "  (transformer): GPTPanguModel(\n",
       "    (wte): Embedding(40000, 1024)\n",
       "    (wpe): Embedding(1024, 1024)\n",
       "    (wqe): Embedding(1024, 1024)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): GPTPanguBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTPanguAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTPanguMLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=40000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=True, use_cache=False)\n",
    "model.resize_token_embeddings(len(tokenizer.sp))\n",
    "model.config.end_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "# model.config.max_length_prompt = 200\n",
    "model.to(device)\n",
    "# print(model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1425170\n"
     ]
    }
   ],
   "source": [
    "f = os.path.join(root, \"Data\", \"raw\", \"baike_qa_train.json\")\n",
    "items = []\n",
    "lens_prompt = []\n",
    "lens_label = []\n",
    "with open(f, \"r\", encoding=\"utf-8\") as r:\n",
    "    while True:\n",
    "        line = r.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        item = json.loads(line.strip(\"\\n\"))\n",
    "        prompt = clean_text(item['title'] if len(item['title']) > len(item['desc']) else item['desc'])\n",
    "        label = clean_text(item['answer'])\n",
    "        items.append(item)\n",
    "        lens_prompt.append(len(prompt))\n",
    "        lens_label.append(len(label))\n",
    "print(len(items))\n",
    "print(np.percentile(lens_prompt, np.arange(90, 101)))\n",
    "print(np.percentile(lens_label, np.arange(90, 101)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qid': 'qid_7770627748113178417',\n",
       " 'category': '生活-保健养生',\n",
       " 'title': '减肥健身我要下载一套很好的有氧健身操，请问哪里有下载地址，谢谢！ ',\n",
       " 'desc': '我要下载一套很好的有氧操，请问哪里有下载地址，谢谢！',\n",
       " 'answer': '我看练太极拳就可以，该运动也是有氧健身的运动，长期锻炼还可以治疗很多慢性病。'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 789\n",
    "items[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我看练太极拳就可以，该运动也是有氧健身的运动，长期锻炼还可以治疗很多慢性病。'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items[i]['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"模型回答：\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_files = os.path.join(root, \"Data\", \"chatgpt\", \"output\", \"sft\", \"pangu-350M\", \"checkpoint-12000\", \"pytorch_model*.bin\")\n",
    "# checkpoint_files = os.path.join(root, \"Data\", \"output\", \"sft\", \"pangu-2.6B\", \"checkpoint-9000\", \"pytorch_model*.bin\")\n",
    "checkpoints = glob.glob(checkpoint_files)\n",
    "st = dict()\n",
    "for checkpoint in checkpoints:\n",
    "    st.update(torch.load(checkpoint, map_location=\"cpu\"))\n",
    "model.load_state_dict(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'GPTPanguForCausalLM' is not supported for . Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel'].\n"
     ]
    }
   ],
   "source": [
    "text_generator = TextGenerationPipeline(model, tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = os.path.join(root, \"Data\", \"raw\", \"baike_qa_train.json\")\n",
    "i = 0\n",
    "prompts = []\n",
    "prompts_processed = []\n",
    "labels = []\n",
    "with open(f, \"r\", encoding=\"utf-8\") as r:\n",
    "    while True:\n",
    "        line = r.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        item = json.loads(line.strip(\"\\n\"))\n",
    "        prompt = clean_text(item['title'] if len(item['title']) > len(item['desc']) else item['desc'])\n",
    "        label = clean_text(item['answer'])\n",
    "        prompt_processed = prompt + tokenizer.sep_token + prefix\n",
    "        prompts.append(prompt)\n",
    "        prompts_processed.append(prompt_processed)\n",
    "        labels.append(label)\n",
    "        i += 1\n",
    "        if i > 1000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 456, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished prediction, time taken: 231.34307527542114\n",
      "prompt: 三相四线直接接线式电表可否接互感器 \n",
      "label: 可以的，但是必须要注意：应该提供三相电表内部电压线圈的供电，最简单的做法就是按互感器的“同名端”正确接入三相表后，再在三相线路每一相互感器的初极（即电路的一次侧）上，接一根线到互感器的次极（即接电表的二次侧）中接入电表的各个进线端的那根线上，这样提供了一个“电压源”给电表后，电度表就可以正常计量了。至于计量方法，则是电表的读数乘上互感器的“变流比”（即初极和次极电流比的值）就为实际用电的数值（KWh）。\n",
      "model answer-0: 可接上导线(零相移一次半以上即中性两点接一线、)二次方都没有三相有一次三相三相零一组接线二回二(可以这样接接零二次)接RC4.因为三分明就是电流呀在接线盒把接地环接出来的二次半左右接一点线二回的二次可以带电阻,三相没一个中性,单相要用0,5电流绕三根粗线零线接接地,中性家用电器等电压一般就是3或者3.5。三连线法的变压器也不是中性地啊单相都中性吗那用铁氧性三相在小铜管前接三相有变压器啊接地地接中性三相?好专业、,求指导学习变压器和接网及配出接插片在此做一表理解我想说学习就做变压器\n",
      "model answer-1: 电表安装完后的连接位置(线柱+相的距离应相等)如果安装后答案应选择A2那么线电流就该加至:LvV∴VF为5kb导体截量(电流I0100p的mA):pLw/mtxBVS电流率AsF+VT,(如lkwV+60mWLzwS5pH则电阻应该与50mA相应于90kWh/80nmolb相比有小量差别如电流是10的电阻才20u则要相差7(*2+/π*n)r是不可逆∴5A等于50+5w所以该种电流计算过程与A2相当选a应没超过5w电表只许输入6只线总也不够50\n",
      "model answer-2: 这方面主要涉及仪表质量问题或者电流继电错误之说TT647-35F有几部分组成啊如果把电压接给5个的那就要三相交流电源串联在一电路中是无法保证PT的测量读数以及使用说明上面所述所提条件也包括实际意义所以只要知道所装测压部分电流信号的回路和电源也确定与电流相合便知会发生多大值多少分之间是否相称为可根据这些可以大概进行推算也没有明显问题在电流输入正常范围以下就是比较危险值和安全标准测量比较正常安全数值比较难做定如果还是难以确定就是人为制造问题可以报警找检修总管维修TL6145B9和2BG1032或接线△9或S68就是这样就能用电表上讲那么具体就是测不准还有电\n",
      "model answer-3: 互感控制部分。用380的电流绕到铁塔里去转到,并连接着的高压接出来之后上有电源线线.低压那面则接线线线槽和铁箍槽;接地网接线是接地环接线与分接地接线同.分相出线在上一个回路进点分别对零进厂供电,如果还有一点上供电线的另一手可接上变高压就需要使用铁脚进站接地的那相线串电阻表和控制板在一个水平线路;电压为200---230的电流电压与它平行接线,接地就行了...还有用导线入箱进行接低压上与地线相地(就是通过电源到高压接线线)在上低压电源变压器接地在上面!把电流的两项加进来就是三芯ic、转换开关也有分交流(\n",
      "model answer-4: 不用单相。互感电压、速度直接转交流电即可满足需要用电势与分度盘连接也不错、直接接上接地或串联来^了在交流小电器方面一般不会损坏了供电可靠不在的要有就用电方便的大家电如高压水器如果还有大商场能有就是配电盒上的继电点好或者直接就挂电线一方面可使用配电时大节省能源更直观可另一方面省去用交流调幅导线就`到这里来给@一个最权威可靠安全且耐用又漂亮,经济环保大实用电工品牌-深圳市鹏利电表生产并引进技术来配套生产变压器(三相供电电源柜内或在地平面处直接接至仪表面板进行接地后通电供电电源不接触外壳等都可以作为低压装置采用:双路输出功率电压、电压互感\n",
      "\n",
      "\n",
      "\n",
      "prompt: 什么东西越生气它就越大？ \n",
      "label: 是：脾气。。。。。。。。。。。。。。。\n",
      "model answer-0: 生气。对所有正常产生危害就比如食物.当然你还有食物没消停到要你没钱啊呵呵不过人就是比较现实..当生活不是所有压力没有压给心的话他就是一天的大事呢吧..在很多话中曰.没有绝对......当一切在面对问题和目标压力过大而得理为心还是算了这曰其实不是我题目说的话而已.可能没怎么生气对人来说也许有时有点难......可是真的发生却不可饶免?因为人心和情感,人总会慢慢被感动..然后就不会对自己这样苛责别人因为这样.如果是不在你需要压力而造成得话也无关系你何必说这个....又什么?这只是人们一常性的感受之一那里能得到解为什么我们总是在追求那些快乐就可以呢要自己给别人呢\n",
      "model answer-1: 人是喜欢变化快慢吧所以有不悦的话请保持不说话好!!哎希望快乐健康的一天。嘻嘻开心起来很精彩的。<进入☆我的音乐欣爆模式即可╮?≤〉...̄°X3z\"′s)b&?4E,a0(\"s,)[X-Ep-QwXz*N]e!/\"\"n*qRqR](X+TX:#1P&y#,gX+wU%mEQLR(m5M3NrRrT4qGvZKsKx3-JjAgEW5m7n%2M+rPsqV!(SfGxE6wNHF5Z\n",
      "model answer-2: 因为心里生气时大脑往往被愤气控制.所以有点像一种化学武器!!但是在有一定深度之基础下,我们不能随便发射出来.我希望楼楼上能帮了我\\什么?这个不能再@。所以现在先解决情绪,去改变。人不就是喜欢去相信和依靠这样被骗之后就很失望失望之后感觉好的!就开心么人最没有心!要知道你不给是对方要和的不是谁逼我让他们做你喜欢你想要努力拼搏追求了这么久我都有感觉你就不要抛弃这样下去只会是失败而且容易一错千百万遍再失败.这样下来还可能影响事业运程我告诉一句其实没问题你们说说如果是你们所要达到什么样人生终点会不会有压力那大家如果真的有,或者不想让你\n",
      "model answer-3: 怒。.越吃米越壮子就是了哈哈我今天跟大狒好一轮儿啊哈哈就说说今天这东西..吃是什么?是人吧又跟女人说有好多种可以不但是别太贱.这样就是很过不去不应该吃...哈哈大点事跟妈似.谁信呀如果没别忍心了谁又能告诉大人们这样坏心情也该好不过那可能只是他自己造成这样对胃太苦了那会真的变身变成人是这样吗因为自己做错个动作呢而且都能这么好!谁能悉了我告诉这好样!就是大胖子吃是饭饭了也好减肥减肥..但就想过意,^0ueu)你喜欢它.不是.很明显嘛都可以用。.这说明自己又想\n",
      "model answer-4: 在这上说一句话让老太太永远记得...说\"是药不是杀鸡呀呀\\它能帮着调理.只要你好好和狗的气啊、好好上个礼什么的话的问题他应该没什么。不要再说.因为我觉得气过伤胎.”那样子...就和打酱油一样很让他们受点惩罚呢—~但千万别忘的他这个意思---让老头不至于不高兴上次带女儿回来..揍我老公了还真吓怕儿子!是呀~~老婆你太激动....也很没有错的如果没有发生不该你带这位老妈的错误现在的后果都大於现在呀呀啊-#(;..!,是呀((&是什么呀)呵呵...其实现在还挺没有这种错--。-啊..(啊。\n",
      "\n",
      "\n",
      "\n",
      "prompt: 南开区哪有卖暖瓶胆的 \n",
      "label: 中环线和王顶堤立交桥交口那有两个土产 里面有 找不到土产的话随便问个人就行了\n",
      "model answer-0: 最好就自己带一点到。而且还很卫生干净不要太乱因为怕有些志愿者拿回一点。还有买时候别听熟行。有些商都很少出便宜水袋但是可以考虑拿这个问价格~希望大家帮帮我们是想给我们身边最好身边有同样问题可以帮到您可以推荐南口商业东安路一带各附楼有一家就会说卖药价格我看到好多店铺还没开估计很多都要改改价格不然那里面就是小广告一个卖东西都看那瓶子暖和度。现在医院医院还有药架。但不一定超市的能吃!我们在附中那吃得到这个价格但我们药店也说什么不能。都快哭天叫地没商开我没看到超市!这个瓶子很麻烦东西最好问他们或者给他们联系好问的时候\n",
      "model answer-1: 一般的学校比较安全,就是小门里面或者寝处附远(不经常呆外面会好说是晚上和天一亮是关门睡觉或开大,关窗户可能不大懂~望理解谢谢。)另外希望您还继续发涨提问内容哦～好了～再回答不知道ing啦～对吧～如果能和小编说,让大家帮理清的话题目是不行╮(#__·～。非常爱你O__IYS】●以上希望没有打扰到任何有良心^。∵这家专卖点真的不咋好看么∏、求一个让我们明白为我们购买东菱手机更好、(有能力一定要购买他们好品牌店。哎()...等等等来着,也求不那么差哦→-V__:33\n",
      "model answer-2: 呵呵去五元庄一买有得多的哦那可能就贵过冰花了,估计可能只有四毛一张那种小钱你给的东西有点太大就看rp来做的~~~还有南院现在出卖气爆声那种还行..那个哎个人没试过就希望那没经验有朋友建议买这个东西价格适我适手,祝运发财喽买的就在去邮乐屋(老城区邮电学校往东三马路走20余公里那~地址在友谊饭店东门前不远那个向海小公园右角就有人了如果没办法还希望你加楼主q53642744这样加ms号可以找到店主联系上为准要给便宜要就给100送一礼品呵呵不要浪费邮的那小家伙...你找一下...我经常去\n",
      "model answer-3: 南坪区五常阳光新城565栋3楼02、23栋有间名为乐业惠,挺大款!去五常五家网一瞧还有好多品种。祝一切顺风如意;乐至你愉天开心吧/请点\"有用建议好评哦#发自网友开心地说-!(用百度就没有人)我买的乐饮不太好...推荐一些~亲.祝你开胜乐多生活~望对采纳有谢啦/!祝您周末过得和你理想生活一般...~乐水一生幸福。祝身体健康.一切安康的乐士也祝愿...所有和善幸福着一切都美好......都是朋友啊你是快乐了一切也同样好朋友我的乐...爱乐,朋友..生活开心地生活我幸福生活....永远地快乐爱是彼此!----是爱吧人\n",
      "model answer-4: 天宁桥市场下面靠近路的左边小广场一单元4(5层811一6084南关加油公司后506栋37012栋的楼(大二区9#307和3133单元门对走);也就是东津石化路口。就是这一个批发货。北塘河东路有一些是比较少些那种在新南三街一区,大概能批发几包!望好评哈;在百度图片上搜可以输入几个点搜索即可得出这些商家~但请见帖!南津批发中心~不可以发广告牌不正规!~发一些优惠或者奖券活动会方便商家和会员之间开展合作嘛请亲提高警惕点在自己去商圈购买时候会感觉有点慢一点,别到的不是太近有骗子~还有个最好去市场转几次\n",
      "\n",
      "\n",
      "\n",
      "prompt: 无意中看到的宣传，所以比较好奇两者有啥区别，还有两者到底是干嘛的，党和广告党请走开\n",
      "label: 百度一下，上面说的很清楚。我个人觉得环境艺术有室内布置设计，规划，家具，园林景观，平面展示等，很多很杂。建筑装饰是对建筑物的设计。环境艺术包含了建筑装饰。\n",
      "model answer-0: 一..两种的含义不可以比....但他们确实被很多人用用;宣传只是其工作职能或是工具手段(主要为了满足社会不可能或不得不做出贡献)2人称和群相一致⁇他们与“新闻标题”关系好比如政治/宗教一政治指什么党党就是某某公司和你之间没有所谓对宗教(如果被说人主政治而有其他看法OR对政工/党就很有意味那还有没OR社会)当然,有意义的目的还有很多!有政治/社会才有钱有时间来玩,那不宣传只是一个功能啦二因为不同政党他们工作侧重及角色等不会比同一类型不新闻有差多拉:所以不要那么对立他们更倾向与一个共同或社会团体\n",
      "model answer-1: 主要不是一样。它都由一群人来运营这个平台来展示他旗人形象、介绍和促进网上交流.在营销中具有宣传效应(让广告信息多了人在购买。达到快速达到效果:如买力广告宣传及大量营销型推广来获取收益及销售和展示)并且与用户能随时同步在博客的“圈子里相互链接访问和对话就比如朋友圈子这样合适而且他们互相有个对话空间、知道你买它不可以通过网络上任何网站就方便得找到同类有针对性交流所以做不起单所以很划拨呵呵。党你看懂你明白!sunmid。].gaoó~cǎorǎ.sǎait〖例1某杂志把某广告媒体\n",
      "model answer-2: 看电视剧党比较无聊也有动力但可能不够执着而看视频主要娱乐、欣赏或交友而已☆、不过没看到也别太狂哈哈还有其他说法和感觉就是没对比啊～还是在用自己感兴趣这两部看看?¥8买是没用、没用用它让我^1起啦1你还相信别人的眼光呀(别人可以把戏拿了呀:“哇1起(买1都可能被我赚,哈哈哈呵,要疯啊〉哈哈～是吧你又骗回来。要你来拿的哦也没有我这样傻呀那是广告而已2广告?不过这个概念,有一定依据我觉得没多少人用啊),那不值得那么狂热而不用这样执着吧哈哈毕竟人\n",
      "model answer-3: 当然了这话一点错误是错误百货、根本不合你当时处身所指了的嘛如果非要选两个说法只能算是\"在国内找点人、给咱忽悠啥,这特是国内宣传一个点广告打一个响)至于啥作用俺估计那不是啥大无畏之论...不过看完它觉得也就一般意思说宣传就是...(...)好么问题扯到外企啦没听说有这样促销之例不象我等就怕在哪碰都挨一次..总有种上不了天门斗下去....下辈子给你滚远啊好为啥咧其实这种在西方、或者某位资深专业杂志经常发,在国内宣传广告其实不算小广告对个人而言无它任何经济拮裕...\n",
      "model answer-4: 宣传语一般为大号之首,用来与品牌打名以赢得第一媒体、为知名公众为售价(相对消费者购买和商场柜台上为卖而商家陈列着卖不明显的名牌品而消费者不买名牌不买了不做买卖为代消事和中介买断收入差价获得利润差价差额以小亏卖、让商场'门儿洞朝&rdquo品牌卖价高出竞争,这都是一个产品营销概念)通过一个电话拨动企业(广告宣传口号在商家招牌上很好的 可以在店面海报等也不显地标配这个品牌和字样都是企业本身就具有个性、或者使用上有这个想法这个时候也叫你客户打广告有很大市场知名度)或者打打电话过去有企业\n",
      "\n",
      "\n",
      "\n",
      "prompt: 飘流幻境的。。。。钱要怎么赚？ \n",
      "label: 掉鱼或挖矿 采木头卖钱\n",
      "model answer-0: 前期一般卖药..如果运子不是很旺会卖出个3~+6卡一个一个卖!运道还可以买武器什么或者药水....我想可以通过练级.刷妖卖卡就已经在积累财富之资你还要刷几个人?5v12还算多了点......不过是我以前最疯狂..你还要不要这样的爽快。在这个地方买1g的话能刷出588k以上装备要30万到现在这个地方每天可消费达15天了最火爆估计得能在30天才能够打回来还没有被偷完哈哈....其实我自己可以过一天这样~赚得最多滴还是运了买3的票一个个侃下来.5卡1.~3元那真是有钱是=...?就因为...所以不玩人\n",
      "model answer-1: 卖魔魂换仙衣换衣,魔道是在大教主、师祖所在区,是大本营地方最好多转啊。不过前提为你和大丐和个,不是为了冲怪、挂机或者练级啊所以啊要练技能哦首先去买个任务道具来打怪了做师奶。一般情况法师就是拿小道具去卖NPC是没必要杀杀法师为主啦但是我去大工会有个地方开一个小店生意超级不错的有不少小任务都被收入任务魔斗换经验去看个地方吧如果大师兄或高帅说有好多玩家是冲去打怪来刷出来仙学、法也不会死就是掉了药还是仙装备还是没有魔什么,到店的旁边打老板问有没便宜要看他自己喽仙的武器就到\n",
      "model answer-2: 开宠物啊～打飞贼的声望,开卖你等级60就卖4元.再过1000天到249.每当1-9等奖的话奖励会更加恐怖2万~33元...一般只要钱打过点(2级怪,50块/次是1倍就打一次要1000多元,100都到~2点奖励.最多100%就把+200倍一次收点2千多万呵呵这样好搞一些呢/也'..不过还是赚钱少赚时间花时间啊...>祝愿喜欢过这个/就玩不出来的都快去赚~嘿嘿*.:o:3J我最多买245张宠和10个小玉*我自己能在8钱一个开2张~很稳吧。哈哈希望不经常说谢谢了啊\n",
      "model answer-3: 建议先去挂绿石换宝石.399/2511:10金30木4+魔防1速度300金150力2攻击1400石800-40万(如果用红魔去绿都没什么攻击上4000左右)魔攻级越贵卖的价值都得提高10%你这个任务给分的话加200敏还高?估计自己挂的话估计在100分内。反正到现在还没收1钱拿着是自己刷任务,用小号钱,浪费RMB还难升级绿魔去就用魔。建议直接放金票再自己找好刷子进.因为都刷出了宝石钱。也不怕跑怪呢就别挂魔1卡好自己加怪了我刚进时,60卡还被迷糊,不过还好到过40分在卖。然后\n",
      "model answer-4: 在逍遥居、如意山两个城都卖药的话你在钱庄收取了30多的押款费到帮派的主钱庄、地穴商人的那个商人、水潭、仙溪,再跟商人打上装备和物品之后在买的话一般来说100都会出精致度装备物品比如+300~250血鬼1双30-65BRL项:粉の护甲等25点力量的灵器和血防法具30件或25套法袍也要用20以上价格的金条30金卡就OKの我这位哥哥朋友以前不就挣1亿多钱么就是个商人(估计有钱会给的吧哈哈...好可怜就说的这么伤感嘛不行就要赚好多银...就没了银...)〈给分50=分\n",
      "\n",
      "\n",
      "\n",
      "prompt: NET源码是什么？ \n",
      "label:   自从比尔·盖茨在2000年提出.NET战略，五六年过去了，人们对到底什么是.NET仍然不是很清楚。这篇文章的目的就是希望能够阐明.NET的内在含意，.NET的缘由以及.NET技术的应用场景。  大家对.NET概念上的迷惑，部分的原因是由于微软自己不十分清晰的市场策略造成的。比如在2000－2002年间，许多微软的产品在发布新版本的时候都在版本上加上了.NET后缀，尽管它们跟.NET技术没有太多关系。现在微软已经意识到这个名称的误用，开始着手把.NET后缀从产品名称中去除。2003年发布的产品中，惟一带有.NET的产品是Visual Studio.NET 2003－微软的集成开发工具。事实上，Visual Studio.NET 2003的下一个版本（代号为Whidbey，将在今年年底发布），它的名称将回归到简单的Visual Studio 2005。 .NET现在可以看成微软的一个品牌。微软有两个非常成功的品牌，那就是Windows和Office。.NET会成为微软的另一个品牌。它不仅仅是一组技术，产品，或服务（微软的服务包括MSN, Passport， MSDN订阅，等等）。一个品牌具有一些特征。比如，Rolex是一个手表品牌，它代表了高质量，时尚，昂贵，成功，等等。那么.NET代表了什么呢？ .NET代表着联通性，敏捷性，和成功。让我分别对这几点来解释一下。 1。联通性。.NET的远景是让所有的事物都连接起来。不管是人，信息，系统，还是设备；不管是一个企业的内部员工，外部合作伙伴，还是客户；不管是Unix, Windows, 还是 Mainframe；不管是SAP, Siebel, 还是 Oracle ERP套件；不管是桌面PC，，还是手表。在一个异构的IT环境里，.NET技术能够将不同的系统连接起来。2。 敏捷性。商务敏捷性和IT敏捷性。面向服务的商务体系结构跟面向服务的IT体系结构很好的配合在一起。SOA (Service-Oriented Architecture)能够给一个企业带来IT敏捷性和商务敏捷性。.NET技术是基于SOA思想和原则设计的，并且采用了像XML和Web Services这些支持应用整合和系统互操作的开放标准。这样，采用.NET技术开发应用，能够带来灵活性和敏捷性。.NET是一个非常合适的技术平台来创建支持SOA体系结构的IT系统并通过这些系统的开发和部署运行达到IT和商务的敏捷性。 3。成功。GE的前主席Jack Welch曾经说过一句话，“在GE，我们只有两个竞争优势：第一，比竞争对手更快的洞悉更多有关客户的信息的能力；第二，比竞争对手更快的将这种理解转化为行动的能力。”最终，IT都是为业务服务的。敏捷带来商务上的成功。.NET可以帮您创建一个敏捷的系统，既容易去洞悉市场，作出战略上的调整，也容易将新的计划付之实行。 这些听上去像是在做市场宣传。但事实确是如此。其它的IT厂商也在谈论这些东西：XML, Web Services, SOA, 敏捷性，联通性，等等。他们可能会使用不同名词，但这些名词后面的含意应该都是非常相似的。所以你可以发现一个有趣的现象，所有IT厂商都支持同样一组开放标准，即XML和Web Services，我们都认可企业应该做SOA，我们都认为敏捷性非常重要。那这些IT厂商之间有什么不同呢？不同之处就在各自的技术实现上。XML, Web Services, 和SOA只是技术规范和技术理念，需要采用一种技术平台才在应用系统中实现这些技术规范和技术理念。各个IT厂商的技术平台有很大的不同。 .NET就是微软的用来实现XML，Web Services, SOA和敏捷性的技术。  对技术人员，想真正了解什么是.NET，必须先了解.NET技术出现的原因和它想解决的问题，必须先了解为什么他们需要XML, Web Services 和 SOA。    技术人员一般将微软看成一个平台厂商。微软通过技术平台，而技术人员在这个技术平台之上创建应用系统。从这个角度，.NET也可以如下来定义： .NET是微软的新一代技术平台，为敏捷商务构建互联互通的应用系统，这些系统是基于标准的，联通的，适应变化的，稳定的和高性能的。   从技术的角度，一个.NET应用是一个运行于.NET Framework之上的应用程序。（更精确的说，一个.NET应用是一个使用.NET Framework类库来编写，并运行于公共语言运行时 Common Language Runtime之上的应用程序。）如果一个应用程序跟.NET Framework无关，它就不能叫做.NET程序。比如，仅仅使用了XML并不就是.NET应用，仅仅使用SOAP SDK调用一个Web Service也不是.NET应用。    微软.NET技术包括哪些东西？核心的东西当然是.NET Framework。 Visual Studio.NET 2002和Visual Studio.NET 2003是创建.NET应用的集成开发环境。Visual Studio For Office (VSTO)可以用来创建基于Word和Excel等文档的.NET解决方案。Web Service Extensions (WSE)是一组支持高级Web Services 标准的.NET类，这些标准包括WS-Security, WS-Policy, WS-ReliableMessaging 和 WS-Attachments，等等。Enterprise Library是一组支持企业级.NET应用程序开发的可重用的应用程序模块，它提供了应用程序开发中需要解决的共性的问题，比如配置管理，数据访问，异常处理，日志管理，等等。   .NET仅仅是跟Web Services相关吗？当然不是。它是微软的新一代技术平台，你可以在这个平台上面创建任何类型的应用系统：传统的Windows桌面应用,Web应用,Office 应用，移动应用，智能设备应用，等等。在一个Pocket PC (Phone Edition)上面，你可以使用.NET Compact Framework （.NET Framework在设备上的一个简化版）创建一个.NET客户端应用程序。或者你可以开发一个.NET移动Web应用，部署在一个IIS Web 服务器上面，然后用户就可以使用Pocket PC (Phone Edition)上面的Internet Explorer 浏览器去访问这个网站，这个网站的页面都是专门为这种设备的小屏幕设计的。 \n",
      "model answer-0: Sentence_online答案。如c++版在abc这一块没的(注意一下sereco.net是7.0,还有net容器等可能性要很大-h++答案里面很多,请参考上面那个SELEF问题解释--d2png】-D3pbp(请见前面)c,h1:wndc:盘/etc注/abbcpg>\"a(noclcirocmp)的解析类文件地址与目标源所在地址重复时编译生成CreationDock标注<encbconp?mod&v>e9_6Cbbbc9?v]e/n,1aA[srcc2u_8pzk32/f2&insernoid.h’lr3\n",
      "model answer-1: 就是网上学习视频制作方法哦学起来是可以有针对性提升效力。教别人学。多学自己是可以摸索一套教学过程学习和动手,学习知识+运用相比较教得人可能效果还钝,学成一个好学一点、进步更快点但是也得根据一个培训项目有专业经验了这个阶段才能更科学实用有更适合,效果更好吧,要有坚持走路吧~,不相信学好学傻,那没底'<ediocatEl》精彩回答还送一个资料。httppanimu.d或yangleshupin0.net分享~你如果采纳!~(是什么地方发图片做头像还发广告哦请直接查看发至最活跃朋友群谢谢啊.,,(这是网站下载过来到我是会员群了请分享发短信!.\n",
      "model answer-2: 一般用FastcMe系统编一些程序比较少用c和p都算数很多汇编在机器翻译文件的应用非常普遍Pre-C还被一些大型游戏厂或游戏联盟做移植程序但c到p只是辅助而无甚多效现在很多企业自己有编译开发流程就可以编译很多常用函数还有个p还支持跨开发网络P2里面最常见还有开发调试器常用和一些虚拟目录系统常用P3比如游戏管理系统V*f(P磐M系统提供使用虚拟磁盘控制文件显示、目录列表修改设置可方便调用功能)目前是开发中6.0发布是2005linuunk论坛2005Wei`iaos平台vt*inxe_Fr2L_Z.so中下载:)这软件要3M哦因为你只需要解压了p3里面\n",
      "model answer-3: ServerService版本文件格式有SepSpacker2和CSV6G文件下载就可以用。1.G3文件是一个文件类型Work-OUmulC(.e.TARNETServicepgIn-LicksectionCastle\"RetEtestKeuse.AUT_JMP:In_J_X_ProPara)--F:3,F盘空数据3.50版本和CSAV61文件一般采用3gCitd9,用cur`盘安装一下2----.iMule--i3----E文件是support版本或RASply4G数据版本或SSSapterInvertrieg6c。现在基本上是不用更新就行:citsd,3gSSSsubt.A。具体有如下:\n",
      "model answer-4: http中:p-tex来转换url等语法来返回purliconcher}如果symlink无法支持这些编码字符就有文件,例如freevering等(这还只能针对simf进行操作和扩展包转至tcl模块内部代码)另外有部分网址cs.injpd生成不了php的文件用什么去开发pgv5或rav文件在我介绍cyclescript页面之后你问我们这是程序和编码器吗!肯定还是的linue、webview都必须为你的机器配置才能被接受和调用,如果编译成任何格式的压缩打包时都不适合apoc、.alp就行了用下面deal语言、fluvage函数来分析看看效果很不好使用这些技巧以后还是用其他地方好吗?要去别\n",
      "\n",
      "\n",
      "\n",
      "prompt: 我注意到有的人每次给人投了赞扬票后都会告诉被投票的人，我投了你赞扬一票。我注意到这种人是有一次我答了那人的问题，我答的在前但那人没有采纳我的，就给我说“我投了你赞扬一票”。什么意思嘛？想堵我的嘴？后来发现那人对别人也是如此，投票后唯恐别人不知道，一定要告诉人家，真是……给别人说这个有什么用？让人记得我的好？反正我给人投了赞扬票是不会说的，心交神往即可，何必弄得这么庸俗？当然，我如果投了别人反对票当然就更不会说了，呵呵。只有一次我告诉了被投票的，我投了呐喊一张反对票，她说你真差劲竟投人反对票，我就说你也可以投我反对票呀，这我注意到有的人每次给人投了赞扬票后都会告诉被投票的人，我投了你赞扬一票。我注意到这种人是有一次我答了那人的问题，我答的在前但那人没有采纳我的，就给我说“我投了你赞扬一票”。什么意思嘛？想堵我的嘴？后来发现那人对别人也是如此，投票后唯恐别人不知道，一定要告诉人家，真是……给别人说这个有什么用？让人记得我的好？反正我给人投了赞扬票是不会说的，心交神往即可，何必弄得这么庸俗？当然，我如果投了别人反对票当然就更不会说了，呵呵。只有一次我告诉了被投票的，我投了呐喊一张反对票，她说你真差劲竟投人反对票，我就说你也可以投我反对票呀，这样我们就扯平了。不过后来她也没有投我反对票。鄙视这种人!自己作弊怕人说就用赞扬票来堵人的嘴。\n",
      "label: 一般不会说的。就像我现在说：“我就不告诉你我投了你反对票”(实际上我根本没投票)\n",
      "model answer-0: 我\n",
      "model answer-1: 有\n",
      "model answer-2: 一般\n",
      "model answer-3: 在\n",
      "model answer-4: 你\n",
      "\n",
      "\n",
      "\n",
      "prompt: 我是个小WX，我在36级左右就把冥之王杀了，做完了修真，当时我以为没什么就没管了，现在都42了，还是元婴，哪位大虾~~~~~~~~告诉我为什么啊？？\n",
      "label: 估计你有修真任务没完吧，看看你还有黄色的任务没。如果没有，系统会自动提示你接39修真的，然后去天城找洞冥仙长就有修真任务了。接过修真任务后需要死一次，然后去破阵北边找鬼仙MM，对话后回天城交差就OK\n",
      "model answer-0: 修真2中打BOSS前要做5个低级术或3D元兵来提高生存能力.这个术是杀5把低级魔后打上得到10w伤害所以我知道是为什么....,其实3和高级盾和金合一练得也挺快而且加2只防御宠的...但技能不能炼成经验技能所以学了前10打BOSS用一个<>2魔.不过那毕竟伤害又不算太多,是打不到底嘛TL还是去搞那个...另外:打法BL门任务要求,需要做50个3和2防御符/,(具体\n",
      "model answer-1: 杀圣魔王也不算事呢1因为元是炼成的~打到后期在可以使用到,再不用元还杀魔能有经验。在你41等级杀圣祖师DEEP应该就是2天。然后过7天去杀黑翼将军BOSS能暴12到180000金到20万2血就比1个冥巫的2秒要来好.所以打妖怪你也多1下好血呢:+6级神魔是不是说要30块能要过妖是吧而且妖会出冥王出来有技能,那要50秒没问题\n",
      "model answer-2: 不在37就杀不了修神还去做完我连杀魔、法师没一个小时打掉NJ~在36以前不要放仙药勉强用一个去修真的去练级用2件打就可以但是这个阶段做为任务所以不可做超过30杀修魔还是不正常现在36杀完3级又杀不到10天还是仙啊魔呀不只修魔这个可以去修真2组到那练练再下在和仙魔2级或2万以上都去升级下吧要下点都不要和魔组队杀一般可以用掉3级下下级下\n",
      "model answer-3: 36级还元没满(或就没有经验再补充一个任务.这样的话建议做40之后修法者,那时在40修真时可以和别的帮派(或修真伙伴加入群妖)。这样比打怪或练法在怪多!性质相对变为好很多而已.经验再多一点会提升2W多点。可以这样看起来很有发展.所以在46修真和35可以做双修吧学好就行了就对FS会更好哦另外还需要学习到很不错得任务呢?还有要和好吗\\法?如果学是可以直接学到40修真\n",
      "model answer-4: 要靠时间去练<-0......不告诉我们~·好怕有危险才做了......其实很重要吧有几个疑问...呵呵做冥金宝宝的练金怪(魔系武器升级最高级10魔4紫0%火6的)去炼兵吧打一打试试我38刚杀过他们啊他们要多经验(100%都做了金装备.10+11金属性.......这不吓吓鬼..要钱钱不要生命....是谁不练才不知道了?都死你们...你们这些骗子还这么忽悠....做吧给RMB卖\n",
      "\n",
      "\n",
      "\n",
      "prompt: 澳洲的一流,如悉尼大学、澳洲国立大学、墨尔本大学，相比其他普通大学，有什么不同？门槛是否一样？名校的哪些方面要求更高？\n",
      "label: 流大学和普通大学的区别 　　　　从很多表面现象上看来，一流大学和普通大学的差别也不是很大，甚至有的时候会感觉到普通大学会比一流大学更好，其实呢，这是比较大学时候的一个误区。 　　第一，毕业生满意程度，以及质量 　　从good university guide来说，一流大学的毕业生满意度和教育质量极低。USYD和UNSW都分别得了三星和二星，MQ的ACTURIAL也不高，还有UMEL,UQ等都不如几所普通大学，比如说，南十字星大学是在纽省毕业生满意度和教育质量最高的。可是，这是客观事实么？ 　　good university guide的评估都是根据调查来的，而这些意见都是很主观的。何为毕业生满意度？何为教育质量? 　　同学们都应该很了解，在我们身边经常可以听到这些话 　　“xx老师不错啊，给分给得很松阿” 　　“这个老师怎么这样，讲那么难的怎么听得懂”等等 　　其实在我们的回答中，满意是否一般并不时按照客观事实来的，如果老师给分给得松，HD,D拿得多，自然会觉得自己的老师好。课程难了，如果自己没有理解，便会很容易联想到是讲师不好，但是有没有设想过，到底是理论本身难度的原因还是主要是因为讲师呢？ 我相信世界上不会有人能够把相对论讲解得让每一个人都明白吧？ 　　在名校名专业中，一般讲师都抓得很紧，课程也会比较难，当然学生会有不满了。而且，澳洲存在一个很大的问题，由于人少，竞争也并不是很激烈，进入名校并不困难，其实进入名校的学生和进入普通大学的学生在能力上可能差距很小，而名校的课程难度显然要比普通大学难得多，学生自然吃不消 　　第二，毕业生就业 　　普通大学一般都是教学生应用为主，而一流大学都是研究为主的，所以教给学生的也更有学术性，名校出来的学生在没有工作经验的前提下，开始工作时并不一定比普通学校的学生容易上手，所以刚出来的学生就业率并不是很高，但是，随着时间的发展，由于基础技能比较扎实，所以更加容易学到新的东西，也更容易得到升迁 　　很多人都说，上名校有什么用，最主要靠的还是自己。这点我同意，只有自己的能力才是真正属于自己的，但是，假设A，B两人，能力都很强，就算他们相等吧，A从名校毕业，B从普通学校毕业，平均成绩都在HD以上，两人去应聘，如果主考官只有时间面试一个人，那么你认为主考官会选谁呢？学校名气不是你的，学校名气并不能代表你的能力，但是无疑学校名气是一块很好的敲门砖。当然了，B的能力如果很强，他自然会找到别的机会，但是他会比A来得辛苦 　　如果想转载本文必须经本站和作者同意，如果想参加澳洲留学相关话题讨论请进入[留学第一站留学澳洲论坛]  \n",
      "model answer-0: 国内名噪澳大利亚之称和一些经济比较繁豪或移民大国国家之间有一种恰当般发展了在国内排名也较稳定等优一些综合大学中最好成绩排名不知道有关系?大学不多只能满足一个目标还是比较好但是大学比较重要但是学校太综合我估计没有人不可以吧你既然不一定就是能找到自己人生比较完美规划就是成功!自己人生的发展很不错的当然自己需要很充分地去满足对不呢所以才知道这个城市有这么有知名度这就跟城市形象这有生我很感激你=希望这也能启发你这要不就是多交很多同学挚友会对提高人伦善为人生起动机吗是吗还有不要\n",
      "model answer-1: 澳洲一般大学水平要求也在世界各地不同学校是一致是在一般性高校当中包括了医学院很多也会分为综合大学甚至公立学府的很多研究项目这些学府研究团队很大当然录用人数很受各个方面学校招生是非常困难(例如学妹学校要考试一般综合院校要入学要先录取但考试不只是单纯标注一些硬性科目要求录取名额等一般不会声称能100来人大录取其实如果招生办是把录取名单通知到学校还是相对比较稳,起码让他们感觉的你的努力值更要被大家知道而非仅仅把我看以为高学杂比校好在各个领域学生整体的发展状态来说他们学校的好不是一上一点二。3好一点\n",
      "model answer-2: 普通高中或以下院校就不会国际交流(除了少数精英和少数特招生招生有学校承认外国研究生签证之外、没有留学生与澳大不同比例比例派录取比例)学生比例不同录取要看当地大学不同但会低于100或者40如果高于就会多很多招生信息:墨尔本大学,维多利亚。。有什么优惠、要求一般等~学校特色各科课程对申请者没有偏、更苛之考出率非常出色(如ielse•LT成绩+英语水平考达到一定比例的录取比值!、或考达到最低80%,更何况一般雅思5.5是很普遍而又常设语言能力部分院校为免IEL而加一个最低7.5分)招生数量会\n",
      "model answer-3: 这些对国际学生最没有难度与条件。中国学生赴外国做大学毕业是相对普通老百姓去私立国际院校而选择一个国内文凭比较钝,与自己职业相关程度最高或者可以和海外生一起到加拿大就读为前提条件,但必须申请学校所授职业要求的学分在150分钟之内并且通过中国国际教育评估认证、并且语言没有口试{必须通过中国外交部领事司翻译、托福ed600-650考到70才能考虑留用澳洲学生必须达到60人才能有选择留学其他院校条件必须达65以上(即要求每一门外语要过国家测试及格,这有什么意思:能参加国内学校里组织学校参加学生课外交流、ucea考试合格\n",
      "model answer-4: 国内高校本科入学比例通常达到70%至96所名大学要求严格澳大利亚著名澳洲院校基本标准:研究生需接受6分、2.分,一般可先向4类申请;其他则分别可以在专业选择、雅思与政治(3等加1.5-9(不受限学额等各种专业加)下自由浮动10)分选择的;且如果学生雅思要求3.5、研究生文凭无专业英语学习(本科除澳洲研究生可先毕业)而转任工作/事业则会要求1倍,这又对毕业或学历提升会相对会增加一大阻力如不转技术的话学历要求则更加宽升可能增加不少在英语口汇培训考试之国内大部分的普通澳大利亚理工,包括澳大利亚其他\n",
      "\n",
      "\n",
      "\n",
      "prompt:      要彻底的把曾经或拷贝的文件删除, 不留任何蛛丝马迹的那种, 就算是拆机也不可能再找到. 特此请求帮助,资料越详细越好.    谢了\n",
      "label: 除了windows本身的卸载程序,还可以下载软件\"完美卸载\"\"文件粉碎机\"\"超级兔子魔法设置\"\"windows优化大师\"很多这样的软件的,有的有\"彻底删除功能\",有的先放到回收站所以注意清空.完了可以用软件清除一下机器垃圾文件.在系统盘中的\"用户\"中 \"我最近使用的文档\"和\"cookies\"等以前的操作痕迹删除,谁也无法知道你曾经和某个文件有过联系,呵呵,我推荐\"超级兔子魔法设置\".如果你还不放心,就格掉你的机器,重做,那更保险.呵呵\n",
      "model answer-0: 不要等吧不做吧等看不见再删除...最好就将这个备份删去不要找...☆备份还是没有备份容易误文件,文件,而会让您永远找上问题....我这建议也适合别人哦如果想彻底一点找一些朋友或家人帮他们把以前东西保存或者干脆把您过去朋友和过,但是找了这些后一定不要再找文件或要恢复删除.....您想想一个有多少回忆啊(比如过去同学们都已分飞?都成故人吗或者还有当年共同有过那曾经最相爱人而又如今还分个两情\n",
      "model answer-1: 你好现在在淘宝交易网上还有什么工具能够从一个地方的服务器取过去呢ddk网址有两个这个我没有搞的对错了可能这问题不会被发现其实他本身并不难的只把软件放到同一界面登陆用那个会清除记录.我把sd硬盘空间恢复成100E后du的硬盘有856M的缓存就不怕被恢复原来容量也不够只del进系统盘是有859多分区了现在就只能到内存格就知道该用空间du还行想必那里对这很精通你有用把光盘和\n",
      "model answer-2: 你是要清RM分区了或去官方里注册硬盘保护手?请在硬盘设置栏把要清除CYG删除点就了你这样还不算是好磁盘文件清零.清理软件清数据不应该清理完数据才能用清分区整理一下看看在搞懂个磁盘基本磁盘整理有方法了一般就是看看启动速度如果慢建议更新驱动比如GentHD、DualsXADEBGF等这些驱动不要乱安装清理了肯定效率不高最好做个CYS文件CNYTAB-STEMANT√FARMABL\n",
      "model answer-3: 去网站里面找到系统程序安装清完就没啦:用磁盘助手的优化助手看看有了。不对用那个卸载软件试试啊,再等等嘛,不会错了就别后悔～别犹豫拉下回删软件试试拉拉呵呵～先看个人喜宜啦____1下(可以下载下下载下来的用啊什么就删也不错..你知道电脑启动没是哪个呀在home,分区盘有啊hadois里安装好吧3先启动先找软件..选择打开)安装.选里面没有软件卸载选择系统卸载和安全恢复可以\n",
      "model answer-4: 用电脑格式form2.shrc>rm4.0332e11,拷贝进UmageRepo后用RamTail删除这个urm.doc(下载在“电脑医生--—彻底清理文件系统问题下载]文件大小不多(大概150B多一点到50)要仔细、不打擦也能干净如果找齐所有文件拷贝进来复制里面有个名为ifilefile这个叫reject的文本格式然后执行c,你要看你需要对哪种文件复制啊、什么啊不要管具体如何下载下载就按电脑所选项,只要里面全是英文\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_return_sequences = 5\n",
    "i = 200\n",
    "j = 210\n",
    "t1 = time.time()\n",
    "results = text_generator(prompts_processed[i:j], max_length=200, num_return_sequences=num_return_sequences,\n",
    "                         do_sample=True, top_k=50, temperature=10.0)\n",
    "print(f\"Finished prediction, time taken: {time.time()-t1}\")\n",
    "\n",
    "for prompt, res, label in zip(prompts[i:j], results[:(j-i)], labels[i:j]):\n",
    "    print(f\"prompt: {prompt}\\nlabel: {label}\")\n",
    "    for k in range(num_return_sequences):\n",
    "        model_answer = res[k]['generated_text'].split(prefix)[1].replace(\"<eot>\", \"\").replace(\"<pad>\", \"\")\n",
    "        print(f\"model answer-{k}: {model_answer}\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: 北大和清华哪个更好？\n",
      "model answer-0: 现在学经济又觉得工科没法学可怕...我们清华北之大类院校每年招收大约5000～60学样生啊什么叫名牌呀他们会出奖学金就有什么名?就等于在这里给清华提供物质生活条件你再能挣一个天大学位证书那可谓如沐雨而知啊再说了就是读的清华还差多少学历才能升大学不进三本博,而是进二本还是专科要学那么厚基础啊能读二所?要看情况一般一本和上大学差几千块^-.这差个1线有几把沾?说要读四年?就可以哎还差几万字的毕业证了还要靠父母拿这些吃低保还是啥好啊要去好些个211学校你就要先多考好多分要你现在考不可能,你也没那功夫给人学个\n",
      "model answer-1: 要读清华最好;北大比北大还要差一点但是清华又以教育和科学为优势因此如果只是学科学,而清华还需要高考考什么来改变就没有任何理由选这一题吧就这个问题就想选对方法最爽快些但高考不能就选择个方法就不能全掌握嘛希望您早日采纳...谢谢支持吧.您这是对北大文科生的不公正提问建议到这个网站首页,提问回答可以查看并与朋友提问相待了您若满意对其他还需要问题可以提出[非常抱歉需要时间发消息,或用百度搜号码搜到了给个提.的.或问QQ@1811447858请见本人提问]:(不含学院名-北京化大学新闻出版.学校资料可以参看北大新闻网上。网址在新闻类的页面即可)另外谢谢\n",
      "model answer-2: 看学生本身素质好才高清华才真特好。看学习好了学生自然也多高考多厉害!要真说你这位学生的话学习是好学校还不该你在这里强争啊强压是多没有什么值得学习的好^自己在心里好好比评嘛学校里学得要真不是一个学生学习到这还是学到这样自己保重为重!!你大学生好好努力学习学习努力你想好就做真的吗要说大学好不好不是你能力有差问题吗就不要整天的挑你学没学学那不如趁早说那该不会北大都是说北大你要真心觉得有一点的那学校很差因为它所讲的话是你没弄懂该信别人的该真不要看大学排名嘛排名好不懂别乱说!但真的能考多不错你想想那个学校好嘛在\n",
      "model answer-3: 从地理范围的划分不同看来讲就是现在学校最中心最核心最具有规模大学:清华其次则外企最核心最有价值专业所在地域则是僻洋之处或远的学校!(如西安地区也比大学比较少和`大=省少但教育好?北大的话:1和人大很熟2、复旦老二在三里,所以很受力`但清华不那么能混:但老一就那么可进是学校最大和高校影响力力度高4都去过清华。但是相对比学校⁇,就自习楼比复旦和西西在学校中处于绝对主力以上都没有听说好!~当然还有:一个个分数有比较靠谱...其实大学没有好坏只要努力一定也有用不是北大你的专业就能用!但它要是用其他大学你选\n",
      "model answer-4: 各有个吧各有好?不同程度而已不过我喜欢,清华可以在高考中以227文科本科第一身份中部大学第二位置第一,全国最好都去的重点大学每年北大是8万$清华一般的有500w不出名要超过700W这个不记得详细地址好像和学费什么联系反正上就两个地方北京还是不知道呢但听楼上的一位校友就觉得在北京也没什么问题那学校名当然又贵又很累的就一个北四和南四哪个不一样在北大上就两本书而且一个本科都不用付那本书的阅读时间也比较灵活大学学不到好书只能让读得上它本科毕业以后再申请。北清不就是说你进的也读得些那嘛现在看,在国内要读好几级考试然后拿国内名字就被刷一下啊还有别选它\n"
     ]
    }
   ],
   "source": [
    "prompt = \"北大和清华哪个更好？\"\n",
    "prompt_processed = prompt + tokenizer.sep_token + prefix\n",
    "num_return_sequences=5\n",
    "res = text_generator(prompt_processed, max_length=200, num_return_sequences=num_return_sequences,\n",
    "                         do_sample=True, top_k=50, temperature=5.0)\n",
    "print(f\"prompt: {prompt}\")\n",
    "for i in range(num_return_sequences):\n",
    "    model_answer = res[i]['generated_text'].split(prefix)[1].replace(\"<eot>\", \"\").replace(\"<pad>\", \"\")\n",
    "    # print(res)\n",
    "    print(f\"model answer-{i}: {model_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_or_path = \"D:\\\\Data\\\\models\\\\pangu-350M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_cache=False, trust_remote_code=True)\n",
    "tokenizer.add_special_tokens({'unk_token': \"<unk>\",\n",
    "                                  'bos_token': \"<s>\",\n",
    "                                  'eos_token': \"<eot>\",\n",
    "                                  'pad_token': \"<pad>\",\n",
    "                                  \"sep_token\": \"<sep>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\SUNZEY~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.501 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "max_length = 1024\n",
    "text = \"你好，你是谁\"\n",
    "# text = \"<|startoftext|>\" + text + \"<|endoftext|>\"\n",
    "res = tokenizer(text, max_length=max_length, truncation=\"longest_first\", \n",
    "          return_tensors=\"pt\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()\n",
    "# torch.cat((res['input_ids'], res['input_ids']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
